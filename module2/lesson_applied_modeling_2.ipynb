{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS7_lesson_applied_modeling_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2ha9OWxf0jw",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 3, Module 2*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-hTictxWYih7"
      },
      "source": [
        "# Applied Modeling, Module 2\n",
        "\n",
        "- Get **permutation importances** for model interpretation and feature selection\n",
        "- Use xgboost for **gradient boosting**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LoxNYFBXYih9"
      },
      "source": [
        "### Default Feature Importances are fast, but Permutation Importances may be more accurate\n",
        "\n",
        "- Permutation Importances\n",
        "  - [Kaggle / Dan Becker: Machine Learning Explainability](https://www.kaggle.com/dansbecker/permutation-importance)\n",
        "  - [Christoph Molnar: Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/feature-importance.html)\n",
        "- (Default) Feature Importances\n",
        "  - [Ando Saabas: Selecting good features, Part 3, Random Forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/)\n",
        "  - [Terence Parr, et al: Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
        "\n",
        "### Try Tree Ensembles when you do machine learning with labeled, tabular data\n",
        "- \"Tree Ensembles\" means Random Forest or **Gradient Boosting** models. \n",
        "- [Tree Ensembles often have the best predictive accuracy](https://arxiv.org/abs/1708.05070) with labeled, tabular data.\n",
        "- Why? Because trees can fit non-linear, non-[monotonic](https://en.wikipedia.org/wiki/Monotonic_function) relationships, and [interactions](https://christophm.github.io/interpretable-ml-book/interaction.html) between features.\n",
        "- A single decision tree, grown to unlimited depth, will [overfit](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/). We solve this problem by ensembling trees, with bagging (Random Forest) or **[boosting](https://www.youtube.com/watch?v=GM3CDQfQ4sw)** (Gradient Boosting).\n",
        "- Random Forest's advantage: may be less sensitive to hyperparameters. **Gradient Boosting's advantage:** may get better predictive accuracy.\n",
        "\n",
        "#### Python libraries for Gradient Boosting\n",
        "- [scikit-learn Gradient Tree Boosting](https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting) — slower than other libraries, but [the new version may be better](https://twitter.com/amuellerml/status/1129443826945396737)\n",
        "  - Anaconda: already installed\n",
        "  - Google Colab: already installed\n",
        "- [xgboost](https://xgboost.readthedocs.io/en/latest/) — can accept missing values and enforce [monotonic constraints](https://xiaoxiaowang87.github.io/monotonicity_constraint/)\n",
        "  - Anaconda, Mac/Linux: `conda install -c conda-forge xgboost`\n",
        "  - Windows: `conda install -c anaconda py-xgboost`\n",
        "  - Google Colab: already installed\n",
        "- [LightGBM](https://lightgbm.readthedocs.io/en/latest/) — can accept missing values and enforce [monotonic constraints](https://blog.datadive.net/monotonicity-constraints-in-machine-learning/)\n",
        "  - Anaconda: `conda install -c conda-forge lightgbm`\n",
        "  - Google Colab: already installed\n",
        "- [CatBoost](https://catboost.ai/) — can accept missing values and use [categorical features](https://catboost.ai/docs/concepts/algorithm-main-stages_cat-to-numberic.html) without preprocessing\n",
        "  - Anaconda: `conda install -c conda-forge catboost`\n",
        "  - Google Colab: `pip install catboost`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMejJg0w8v76",
        "colab_type": "text"
      },
      "source": [
        "### Setup\n",
        "\n",
        "You can work locally (follow the [local setup instructions](https://lambdaschool.github.io/ds/unit2/local/)) or on Colab (run the code cell below)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BFQMky3CYih-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b561efb3-828a-4e2a-842e-cc1478955953"
      },
      "source": [
        "import os, sys\n",
        "in_colab = 'google.colab' in sys.modules\n",
        "\n",
        "# If you're in Colab...\n",
        "if in_colab:\n",
        "    # Pull files from Github repo\n",
        "    os.chdir('/content')\n",
        "    !git init .\n",
        "    !git remote add origin https://github.com/LambdaSchool/DS-Unit-2-Applied-Modeling.git\n",
        "    !git pull origin master\n",
        "    \n",
        "    # Install required python packages\n",
        "    !pip install -r requirements.txt\n",
        "    \n",
        "    # Change into directory for module\n",
        "    os.chdir('module2')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reinitialized existing Git repository in /content/.git/\n",
            "fatal: remote origin already exists.\n",
            "From https://github.com/LambdaSchool/DS-Unit-2-Applied-Modeling\n",
            " * branch            master     -> FETCH_HEAD\n",
            "Already up to date.\n",
            "Requirement already satisfied: category_encoders==2.0.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: eli5==0.10.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.10.1)\n",
            "Requirement already satisfied: matplotlib!=3.1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (3.0.3)\n",
            "Requirement already satisfied: pandas-profiling==2.3.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (2.3.0)\n",
            "Requirement already satisfied: pdpbox==0.2.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: plotly==4.1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (4.1.1)\n",
            "Requirement already satisfied: seaborn==0.9.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (0.9.0)\n",
            "Requirement already satisfied: scikit-learn==0.21.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (0.21.3)\n",
            "Requirement already satisfied: shap==0.30.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (0.30.0)\n",
            "Requirement already satisfied: xgboost==0.90 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (0.90)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (1.16.5)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (0.24.2)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (0.5.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (1.12.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (0.10.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (0.8.5)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (19.1.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (2.10.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.1.1->-r requirements.txt (line 3)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.1.1->-r requirements.txt (line 3)) (2.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.1.1->-r requirements.txt (line 3)) (2.5.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.1.1->-r requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: phik>=0.9.8 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.9.8)\n",
            "Requirement already satisfied: astropy in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.3.0->-r requirements.txt (line 4)) (3.0.5)\n",
            "Requirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.4.2)\n",
            "Requirement already satisfied: confuse>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.0.0)\n",
            "Requirement already satisfied: htmlmin>=0.1.12 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.1.12)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from pdpbox==0.2.0->-r requirements.txt (line 5)) (5.4.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from pdpbox==0.2.0->-r requirements.txt (line 5)) (0.13.2)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly==4.1.1->-r requirements.txt (line 6)) (1.3.3)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.6/dist-packages (from shap==0.30.0->-r requirements.txt (line 9)) (4.28.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from shap==0.30.0->-r requirements.txt (line 9)) (5.5.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from shap==0.30.0->-r requirements.txt (line 9)) (0.15.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders==2.0.0->-r requirements.txt (line 1)) (2018.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eli5==0.10.1->-r requirements.txt (line 2)) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.1.1->-r requirements.txt (line 3)) (41.2.0)\n",
            "Requirement already satisfied: pytest-pylint>=0.13.0 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.14.1)\n",
            "Requirement already satisfied: jupyter-client>=5.2.3 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (5.3.3)\n",
            "Requirement already satisfied: pytest>=4.0.2 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (5.2.0)\n",
            "Requirement already satisfied: numba>=0.38.1 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.40.1)\n",
            "Requirement already satisfied: nbconvert>=5.3.1 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (5.6.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from confuse>=1.0.0->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (3.13)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (4.3.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (1.0.16)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (2.1.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (4.4.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (4.7.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (0.8.1)\n",
            "Requirement already satisfied: imageio>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (1.0.3)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (2.3)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (4.3.0)\n",
            "Requirement already satisfied: pylint>=1.4.5 in /usr/local/lib/python3.6/dist-packages (from pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (2.4.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (17.0.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (4.5.0)\n",
            "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (4.5.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.1.7)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.8.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.23)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (7.2.0)\n",
            "Requirement already satisfied: pluggy<1.0,>=0.12 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.13.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (19.2)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.29.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.4.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.6.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.4.2)\n",
            "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (4.4.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.8.4)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->shap==0.30.0->-r requirements.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->shap==0.30.0->-r requirements.txt (line 9)) (0.6.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.3.0->scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (0.46)\n",
            "Requirement already satisfied: astroid<2.4,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (2.3.1)\n",
            "Requirement already satisfied: isort<5,>=4.2.5 in /usr/local/lib/python3.6/dist-packages (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (4.3.21)\n",
            "Requirement already satisfied: mccabe<0.7,>=0.6 in /usr/local/lib/python3.6/dist-packages (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.6.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (2.6.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.5.1)\n",
            "Requirement already satisfied: typed-ast<1.5,>=1.4.0; implementation_name == \"cpython\" and python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from astroid<2.4,>=2.3.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.4.0)\n",
            "Requirement already satisfied: lazy-object-proxy==1.4.* in /usr/local/lib/python3.6/dist-packages (from astroid<2.4,>=2.3.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.4.2)\n",
            "Requirement already satisfied: wrapt==1.11.* in /usr/local/lib/python3.6/dist-packages (from astroid<2.4,>=2.3.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.11.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-TExplb_Slf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Merge train_features.csv & train_labels.csv\n",
        "train = pd.merge(pd.read_csv('../data/tanzania/train_features.csv'), \n",
        "                 pd.read_csv('../data/tanzania/train_labels.csv'))\n",
        "\n",
        "# Read test_features.csv & sample_submission.csv\n",
        "test = pd.read_csv('../data/tanzania/test_features.csv')\n",
        "sample_submission = pd.read_csv('../data/tanzania/sample_submission.csv')\n",
        "\n",
        "\n",
        "# Split train into train & val\n",
        "train, val = train_test_split(train, train_size=0.80, test_size=0.20, \n",
        "                              stratify=train['status_group'], random_state=42)\n",
        "\n",
        "\n",
        "def wrangle(X):\n",
        "    \"\"\"Wrangle train, validate, and test sets in the same way\"\"\"\n",
        "    \n",
        "    # Prevent SettingWithCopyWarning\n",
        "    X = X.copy()\n",
        "    \n",
        "    # About 3% of the time, latitude has small values near zero,\n",
        "    # outside Tanzania, so we'll treat these values like zero.\n",
        "    X['latitude'] = X['latitude'].replace(-2e-08, 0)\n",
        "    \n",
        "    # When columns have zeros and shouldn't, they are like null values.\n",
        "    # So we will replace the zeros with nulls, and impute missing values later.\n",
        "    # Also create a \"missing indicator\" column, because the fact that\n",
        "    # values are missing may be a predictive signal.\n",
        "    cols_with_zeros = ['longitude', 'latitude', 'construction_year', \n",
        "                       'gps_height', 'population']\n",
        "    for col in cols_with_zeros:\n",
        "        X[col] = X[col].replace(0, np.nan)\n",
        "        X[col+'_MISSING'] = X[col].isnull()\n",
        "            \n",
        "    # Drop duplicate columns\n",
        "    duplicates = ['quantity_group', 'payment_type']\n",
        "    X = X.drop(columns=duplicates)\n",
        "    \n",
        "    # Drop recorded_by (never varies) and id (always varies, random)\n",
        "    unusable_variance = ['recorded_by', 'id']\n",
        "    X = X.drop(columns=unusable_variance)\n",
        "    \n",
        "    # Convert date_recorded to datetime\n",
        "    X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format=True)\n",
        "    \n",
        "    # Extract components from date_recorded, then drop the original column\n",
        "    X['year_recorded'] = X['date_recorded'].dt.year\n",
        "    X['month_recorded'] = X['date_recorded'].dt.month\n",
        "    X['day_recorded'] = X['date_recorded'].dt.day\n",
        "    X = X.drop(columns='date_recorded')\n",
        "    \n",
        "    # Engineer feature: how many years from construction_year to date_recorded\n",
        "    X['years'] = X['year_recorded'] - X['construction_year']\n",
        "    X['years_MISSING'] = X['years'].isnull()\n",
        "    \n",
        "    # return the wrangled dataframe\n",
        "    return X\n",
        "\n",
        "train = wrangle(train)\n",
        "val = wrangle(val)\n",
        "test = wrangle(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhg8PQKt_jzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Arrange data into X features matrix and y target vector\n",
        "target = 'status_group'\n",
        "X_train = train.drop(columns=target)\n",
        "y_train = train[target]\n",
        "X_val = val.drop(columns=target)\n",
        "y_val = val[target]\n",
        "X_test = test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8lB4z5l_eml",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "988c1f0d-0bd5-4336-ba7b-a9a9f2b2949b"
      },
      "source": [
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8135521885521886\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7HOayKBOYiit"
      },
      "source": [
        "# 3 types of feature importances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4bRhsxENYiiu"
      },
      "source": [
        "## 1. (Default) Feature Importances\n",
        "\n",
        "Fastest, good for first estimates, but be aware:\n",
        "\n",
        "\n",
        "\n",
        ">**When the dataset has two (or more) correlated features, then from the point of view of the model, any of these correlated features can be used as the predictor, with no concrete preference of one over the others.** But once one of them is used, the importance of others is significantly reduced since effectively the impurity they can remove is already removed by the first feature. As a consequence, they will have a lower reported importance. This is not an issue when we want to use feature selection to reduce overfitting, since it makes sense to remove features that are mostly duplicated by other features. But when interpreting the data, it can lead to the incorrect conclusion that one of the variables is a strong predictor while the others in the same group are unimportant, while actually they are very close in terms of their relationship with the response variable. — [Selecting good features – Part III: random forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/) \n",
        "\n",
        "\n",
        " \n",
        " > **The scikit-learn Random Forest feature importance ... tends to inflate the importance of continuous or high-cardinality categorical variables.** ... Breiman and Cutler, the inventors of Random Forests, indicate that this method of “adding up the gini decreases for each individual variable over all trees in the forest gives a **fast** variable importance that is often very consistent with the permutation importance measure.” —  [Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
        "\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BNVm6f7mYiiu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "51aa1d29-2615-465a-a371-4f366b2b9410"
      },
      "source": [
        "# Get feature importances\n",
        "rf = pipeline.named_steps['randomforestclassifier']\n",
        "importances = pd.Series(rf.feature_importances_, X_train.columns)\n",
        "\n",
        "# Plot feature importances\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 20\n",
        "plt.figure(figsize=(10,n/2))\n",
        "plt.title(f'Top {n} features')\n",
        "importances.sort_values()[-n:].plot.barh(color='grey');"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArkAAAJOCAYAAACzyR8VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n99A0istCZwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y8HzLcCBYiiv"
      },
      "source": [
        "## 2. Drop-Column Importance\n",
        "\n",
        "The best in theory, but too slow in practice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DQAOlERnYiiw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "9217e198-123d-493f-ce54-497758853e6a"
      },
      "source": [
        "column  = 'quantity'\n",
        "\n",
        "# Fit without column\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "pipeline.fit(X_train.drop(columns=column), y_train)\n",
        "score_without = pipeline.score(X_val.drop(columns=column), y_val)\n",
        "print(f'Validation Accuracy without {column}: {score_without}')\n",
        "\n",
        "# Fit with column\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "pipeline.fit(X_train, y_train)\n",
        "score_with = pipeline.score(X_val, y_val)\n",
        "print(f'Validation Accuracy with {column}: {score_with}')\n",
        "\n",
        "# Compare the error with & without column\n",
        "print(f'Drop-Column Importance for {column}: {score_with - score_without}')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy without quantity: 0.7771043771043771\n",
            "Validation Accuracy with quantity: 0.8135521885521886\n",
            "Drop-Column Importance for quantity: 0.03644781144781151\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6Vu39wGkYiix"
      },
      "source": [
        "## 3. Permutation Importance\n",
        "\n",
        "Permutation Importance is a good compromise between Feature Importance based on impurity reduction (which is the fastest) and Drop Column Importance (which is the \"best.\")\n",
        "\n",
        "[The ELI5 library documentation explains,](https://eli5.readthedocs.io/en/latest/blackbox/permutation_importance.html)\n",
        "\n",
        "> Importance can be measured by looking at how much the score (accuracy, F1, R^2, etc. - any score we’re interested in) decreases when a feature is not available.\n",
        ">\n",
        "> To do that one can remove feature from the dataset, re-train the estimator and check the score. But it requires re-training an estimator for each feature, which can be computationally intensive. ...\n",
        ">\n",
        ">To avoid re-training the estimator we can remove a feature only from the test part of the dataset, and compute score without using this feature. It doesn’t work as-is, because estimators expect feature to be present. So instead of removing a feature we can replace it with random noise - feature column is still there, but it no longer contains useful information. This method works if noise is drawn from the same distribution as original feature values (as otherwise estimator may fail). The simplest way to get such noise is to shuffle values for a feature, i.e. use other examples’ feature values - this is how permutation importance is computed.\n",
        ">\n",
        ">The method is most suitable for computing feature importances when a number of columns (features) is not huge; it can be resource-intensive otherwise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GYCiEx7zYiiy"
      },
      "source": [
        "### Do-It-Yourself way, for intuition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TksOf_n2Yiiy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "c36476b9-bbb9-475b-cf2d-5ce8027d4427"
      },
      "source": [
        "feature = 'quantity'\n",
        "X_val[feature].head()\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3290     insufficient\n",
              "47666    insufficient\n",
              "2538           enough\n",
              "53117          enough\n",
              "51817          enough\n",
              "Name: quantity, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCfr91vsurSr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "8e7d1013-dfe2-4591-b00b-22540d09d767"
      },
      "source": [
        "X_val[feature].value_counts()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "enough          6619\n",
              "insufficient    2976\n",
              "dry             1325\n",
              "seasonal         806\n",
              "unknown          154\n",
              "Name: quantity, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYl8nkTpuzL_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_val_permuted = X_val.copy()\n",
        "X_val_permuted[feature] = np.random.permutation(X_val[feature])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aO7G0F_vRcr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "ebd32c92-8834-4fdf-9ccf-a0a279ec0063"
      },
      "source": [
        "X_val_permuted[feature].head()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3290           enough\n",
              "47666    insufficient\n",
              "2538              dry\n",
              "53117          enough\n",
              "51817          enough\n",
              "Name: quantity, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6WlnEFCvVt6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "c894df47-d6d4-477d-9e9e-92f3580892c3"
      },
      "source": [
        "X_val_permuted[feature].value_counts()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "enough          6619\n",
              "insufficient    2976\n",
              "dry             1325\n",
              "seasonal         806\n",
              "unknown          154\n",
              "Name: quantity, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAFqgtglvcQE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "267bf289-0a68-4763-c8f5-ab247d280286"
      },
      "source": [
        "score_permuted = pipeline.score(X_val_permuted, y_val)\n",
        "\n",
        "print(f'Validation Accuracy with {feature}: {score_with}')\n",
        "print(f'Validation Accuracy with {feature} permuted: {score_permuted}')\n",
        "print(f'Validation Accuracy with {score_with - score_permuted}')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy with quantity: 0.8135521885521886\n",
            "Validation Accuracy with quantity permuted: 0.710942760942761\n",
            "Validation Accuracy with 0.1026094276094276\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0LYk19SNYii7"
      },
      "source": [
        "### With eli5 library\n",
        "\n",
        "For more documentation on using this library, see:\n",
        "- [eli5.sklearn.PermutationImportance](https://eli5.readthedocs.io/en/latest/autodocs/sklearn.html#eli5.sklearn.permutation_importance.PermutationImportance)\n",
        "- [eli5.show_weights](https://eli5.readthedocs.io/en/latest/autodocs/eli5.html#eli5.show_weights)\n",
        "- [scikit-learn user guide, `scoring` parameter](https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules)\n",
        "\n",
        "eli5 doesn't work with pipelines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpSemTkFFP8i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "c06f3e2d-caa8-41ee-e0f4-20498ca4f68a"
      },
      "source": [
        "transformers = make_pipeline(\n",
        "    ce.OrdinalEncoder(),\n",
        "    SimpleImputer(strategy='median')\n",
        ")\n",
        "\n",
        "X_train_transformed = transformers.fit_transform(X_train)\n",
        "X_val_transformed = transformers.fit_transform(X_val)\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "model.fit(X_train_transformed, y_train)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS5Kzu8pw6fd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        },
        "outputId": "14261ff4-fc87-4be8-ccd1-e2b160302c29"
      },
      "source": [
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "\n",
        "permuter = PermutationImportance(\n",
        "    model, \n",
        "    scoring='accuracy',\n",
        "    n_iter=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "permuter.fit(X_val_transformed, y_val)\n",
        "feature_names = X_val.columns.tolist()\n",
        "\n",
        "eli5.show_weights(\n",
        "    permuter,\n",
        "    top=None,\n",
        "    feature_names = feature_names\n",
        ")\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
              "    <thead>\n",
              "    <tr style=\"border: none;\">\n",
              "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
              "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "    </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.1007\n",
              "                \n",
              "                    &plusmn; 0.0002\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                quantity\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.83%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0107\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                amount_tsh\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.95%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0103\n",
              "                \n",
              "                    &plusmn; 0.0002\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                extraction_type_class\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.99%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0101\n",
              "                \n",
              "                    &plusmn; 0.0006\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                waterpoint_type\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.18%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0095\n",
              "                \n",
              "                    &plusmn; 0.0016\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                longitude\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.70%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0077\n",
              "                \n",
              "                    &plusmn; 0.0015\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                latitude\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.86%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0072\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                waterpoint_type_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.13%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0063\n",
              "                \n",
              "                    &plusmn; 0.0006\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                population\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.07%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0036\n",
              "                \n",
              "                    &plusmn; 0.0035\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                construction_year\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.15%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0034\n",
              "                \n",
              "                    &plusmn; 0.0013\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                subvillage\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.36%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0028\n",
              "                \n",
              "                    &plusmn; 0.0006\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                public_meeting\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.38%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0028\n",
              "                \n",
              "                    &plusmn; 0.0032\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                years\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.41%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0027\n",
              "                \n",
              "                    &plusmn; 0.0012\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                payment\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.50%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0025\n",
              "                \n",
              "                    &plusmn; 0.0018\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                day_recorded\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.70%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0020\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                gps_height\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.72%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0020\n",
              "                \n",
              "                    &plusmn; 0.0004\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                district_code\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.80%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0018\n",
              "                \n",
              "                    &plusmn; 0.0006\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                source\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.09%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0012\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                extraction_type_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.16%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0011\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                funder\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.16%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0011\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                permit\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.18%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0011\n",
              "                \n",
              "                    &plusmn; 0.0018\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                region\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.30%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0008\n",
              "                \n",
              "                    &plusmn; 0.0022\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                management\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.30%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0008\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                extraction_type\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.32%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0008\n",
              "                \n",
              "                    &plusmn; 0.0009\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                longitude_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.35%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0008\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                wpt_name\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.35%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0008\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                ward\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.37%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0007\n",
              "                \n",
              "                    &plusmn; 0.0013\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                year_recorded\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.43%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0006\n",
              "                \n",
              "                    &plusmn; 0.0004\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                lga\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.45%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0006\n",
              "                \n",
              "                    &plusmn; 0.0010\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                water_quality\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.54%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0006\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                construction_year_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.57%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0004\n",
              "                \n",
              "                    &plusmn; 0.0012\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                region_code\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.60%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0004\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                years_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.60%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0004\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                source_class\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.63%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                num_private\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.66%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                scheme_name\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.73%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0002\n",
              "                \n",
              "                    &plusmn; 0.0013\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                scheme_management\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.73%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0002\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                population_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.73%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0002\n",
              "                \n",
              "                    &plusmn; 0.0024\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                month_recorded\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.81%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                latitude_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0000\n",
              "                \n",
              "                    &plusmn; 0.0002\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                management_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0000\n",
              "                \n",
              "                    &plusmn; 0.0007\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                gps_height_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.91%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0000\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                source_type\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.57%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0004\n",
              "                \n",
              "                    &plusmn; 0.0010\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                installer\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.35%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0008\n",
              "                \n",
              "                    &plusmn; 0.0010\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                quality_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 98.90%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0016\n",
              "                \n",
              "                    &plusmn; 0.0007\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                basin\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "    \n",
              "    </tbody>\n",
              "</table>\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q07yW9k-Yii8"
      },
      "source": [
        "### We can use importances for feature selection\n",
        "\n",
        "For example, we can remove features with zero importance. The model trains faster and the score does not decrease."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tZrPFyEMYii9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c674bcc7-13e3-4707-c2d7-1ff1425981e1"
      },
      "source": [
        "minimum_importance = 0\n",
        "mask = permuter.feature_importances_ > minimum_importance\n",
        "feature = X_train.columns[mask]\n",
        "X_train = X_train[feature]\n",
        "\n",
        "X_train.shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47520, 39)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YydEjk0wzb28",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "51bdda6a-9b22-4778-956a-2a7113285b6c"
      },
      "source": [
        "X_val = X_val[feature]\n",
        "X_val.shape"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11880, 39)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5LFIzv3zhQ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8641ef1c-ba08-45a0-a256-e811c6d17e59"
      },
      "source": [
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(),\n",
        "    SimpleImputer(strategy='median'),\n",
        "    RandomForestClassifier(n_estimators=100,random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy:', pipeline.score(X_val, y_val))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.8125420875420876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fl67bCR7WY6j",
        "colab_type": "text"
      },
      "source": [
        "# Use xgboost for gradient boosting\n",
        "\n",
        "\n",
        "#### [XGBoost Python API Reference: Scikit-Learn API](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn)+"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsnJRKjfWYph",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "c5a50826-fe8b-40d2-de2a-dd860f4f11bb"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(),\n",
        "    XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "\n",
        "pipeline.fit(X_train, y_train)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('ordinalencoder',\n",
              "                 OrdinalEncoder(cols=['funder', 'wpt_name', 'subvillage',\n",
              "                                      'region', 'lga', 'ward', 'public_meeting',\n",
              "                                      'scheme_management', 'scheme_name',\n",
              "                                      'permit', 'extraction_type',\n",
              "                                      'extraction_type_group',\n",
              "                                      'extraction_type_class', 'management',\n",
              "                                      'payment', 'water_quality', 'quantity',\n",
              "                                      'source', 'source_class',\n",
              "                                      'waterpoint_type',\n",
              "                                      'waterpoin...\n",
              "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                               colsample_bylevel=1, colsample_bynode=1,\n",
              "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
              "                               max_delta_step=0, max_depth=3,\n",
              "                               min_child_weight=1, missing=None,\n",
              "                               n_estimators=100, n_jobs=-1, nthread=None,\n",
              "                               objective='multi:softprob', random_state=42,\n",
              "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "                               seed=None, silent=None, subsample=1,\n",
              "                               verbosity=1))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQt3p1ye05L0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6caaa1aa-b568-4838-a89e-e9b858ac4b66"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = pipeline.predict(X_val)\n",
        "print('Validation Accuracy: ', accuracy_score(y_val, y_pred))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy:  0.7457070707070707\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubb7Ot6OZcK1",
        "colab_type": "text"
      },
      "source": [
        "### Understand the difference between boosting & bagging\n",
        "\n",
        "Boosting (used by Gradient Boosting) is different than Bagging (used by Random Forests). \n",
        "\n",
        "[_An Introduction to Statistical Learning_](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf) Chapter 8.2.3, Boosting:\n",
        "\n",
        ">Recall that bagging involves creating multiple copies of the original training data set using the bootstrap, fitting a separate decision tree to each copy, and then combining all of the trees in order to create a single predictive model.\n",
        ">\n",
        ">**Boosting works in a similar way, except that the trees are grown _sequentially_: each tree is grown using information from previously grown trees.**\n",
        ">\n",
        ">Unlike fitting a single large decision tree to the data, which amounts to _fitting the data hard_ and potentially overfitting, the boosting approach instead _learns slowly._ Given the current model, we fit a decision tree to the residuals from the model.\n",
        ">\n",
        ">We then add this new decision tree into the fitted function in order to update the residuals. Each of these trees can be rather small, with just a few terminal nodes. **By fitting small trees to the residuals, we slowly improve fˆ in areas where it does not perform well.**\n",
        ">\n",
        ">Note that in boosting, unlike in bagging, the construction of each tree depends strongly on the trees that have already been grown."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCjVSlD_XJr2",
        "colab_type": "text"
      },
      "source": [
        "#### [Avoid Overfitting By Early Stopping With XGBoost In Python](https://machinelearningmastery.com/avoid-overfitting-by-early-stopping-with-xgboost-in-python/)\n",
        "\n",
        "Why is early stopping better than a For loop, or GridSearchCV, to optimize `n_estimators`?\n",
        "\n",
        "With early stopping, if `n_iterations` is our number of iterations, then we fit `n_iterations` decision trees.\n",
        "\n",
        "With a for loop, or GridSearchCV, we'd fit `sum(range(1,n_rounds+1))` trees.\n",
        "\n",
        "But it doesn't work well with pipelines. You may need to re-run multiple times with different values of other parameters such as `max_depth` and `learning_rate`.\n",
        "\n",
        "#### XGBoost parameters\n",
        "- [Notes on parameter tuning](https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html)\n",
        "- [Parameters documentation](https://xgboost.readthedocs.io/en/latest/parameter.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNX3IKftXBFS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "44c2d898-3cbc-4093-84cb-b5c2d63d5d0c"
      },
      "source": [
        "encoder = ce.OrdinalEncoder()\n",
        "X_train_encoded = encoder.fit_transform(X_train)\n",
        "X_val_encoded = encoder.transform(X_val)\n",
        "\n",
        "X_train.shape, X_val.shape, X_train_encoded.shape, X_val_encoded.shape"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((47520, 39), (11880, 39), (47520, 39), (11880, 39))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hb4l9kq43b4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_set = [(X_train_encoded, y_train), (X_val_encoded, y_val)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQd_8NJY3RaP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ae8d26fd-30b2-4e8a-f42b-196a5f79129d"
      },
      "source": [
        "model = XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=7,\n",
        "    learning_rate=0.1,\n",
        "    j_jobs=-1\n",
        ")\n",
        "\n",
        "model.fit(X_train_encoded, y_train, eval_set=eval_set, eval_metric='merror', early_stopping_rounds=50)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-merror:0.250884\tvalidation_1-merror:0.261953\n",
            "Multiple eval metrics have been passed: 'validation_1-merror' will be used for early stopping.\n",
            "\n",
            "Will train until validation_1-merror hasn't improved in 50 rounds.\n",
            "[1]\tvalidation_0-merror:0.252294\tvalidation_1-merror:0.264057\n",
            "[2]\tvalidation_0-merror:0.251747\tvalidation_1-merror:0.264731\n",
            "[3]\tvalidation_0-merror:0.249895\tvalidation_1-merror:0.262037\n",
            "[4]\tvalidation_0-merror:0.248864\tvalidation_1-merror:0.26069\n",
            "[5]\tvalidation_0-merror:0.24678\tvalidation_1-merror:0.257239\n",
            "[6]\tvalidation_0-merror:0.243687\tvalidation_1-merror:0.255051\n",
            "[7]\tvalidation_0-merror:0.240404\tvalidation_1-merror:0.250421\n",
            "[8]\tvalidation_0-merror:0.2379\tvalidation_1-merror:0.248316\n",
            "[9]\tvalidation_0-merror:0.235816\tvalidation_1-merror:0.247054\n",
            "[10]\tvalidation_0-merror:0.234975\tvalidation_1-merror:0.24596\n",
            "[11]\tvalidation_0-merror:0.23388\tvalidation_1-merror:0.245118\n",
            "[12]\tvalidation_0-merror:0.233228\tvalidation_1-merror:0.245286\n",
            "[13]\tvalidation_0-merror:0.231776\tvalidation_1-merror:0.244529\n",
            "[14]\tvalidation_0-merror:0.232008\tvalidation_1-merror:0.244529\n",
            "[15]\tvalidation_0-merror:0.230535\tvalidation_1-merror:0.243855\n",
            "[16]\tvalidation_0-merror:0.229104\tvalidation_1-merror:0.241835\n",
            "[17]\tvalidation_0-merror:0.228325\tvalidation_1-merror:0.241919\n",
            "[18]\tvalidation_0-merror:0.227125\tvalidation_1-merror:0.239899\n",
            "[19]\tvalidation_0-merror:0.226515\tvalidation_1-merror:0.238973\n",
            "[20]\tvalidation_0-merror:0.225526\tvalidation_1-merror:0.238973\n",
            "[21]\tvalidation_0-merror:0.224495\tvalidation_1-merror:0.237626\n",
            "[22]\tvalidation_0-merror:0.22298\tvalidation_1-merror:0.23569\n",
            "[23]\tvalidation_0-merror:0.221843\tvalidation_1-merror:0.235522\n",
            "[24]\tvalidation_0-merror:0.221044\tvalidation_1-merror:0.235774\n",
            "[25]\tvalidation_0-merror:0.220244\tvalidation_1-merror:0.235269\n",
            "[26]\tvalidation_0-merror:0.218939\tvalidation_1-merror:0.234428\n",
            "[27]\tvalidation_0-merror:0.217151\tvalidation_1-merror:0.232492\n",
            "[28]\tvalidation_0-merror:0.215109\tvalidation_1-merror:0.230892\n",
            "[29]\tvalidation_0-merror:0.213636\tvalidation_1-merror:0.229882\n",
            "[30]\tvalidation_0-merror:0.212563\tvalidation_1-merror:0.228283\n",
            "[31]\tvalidation_0-merror:0.211132\tvalidation_1-merror:0.227357\n",
            "[32]\tvalidation_0-merror:0.209996\tvalidation_1-merror:0.227104\n",
            "[33]\tvalidation_0-merror:0.209049\tvalidation_1-merror:0.226683\n",
            "[34]\tvalidation_0-merror:0.207765\tvalidation_1-merror:0.226515\n",
            "[35]\tvalidation_0-merror:0.206734\tvalidation_1-merror:0.226347\n",
            "[36]\tvalidation_0-merror:0.205724\tvalidation_1-merror:0.225589\n",
            "[37]\tvalidation_0-merror:0.204882\tvalidation_1-merror:0.225168\n",
            "[38]\tvalidation_0-merror:0.203998\tvalidation_1-merror:0.224158\n",
            "[39]\tvalidation_0-merror:0.20221\tvalidation_1-merror:0.222475\n",
            "[40]\tvalidation_0-merror:0.200968\tvalidation_1-merror:0.221633\n",
            "[41]\tvalidation_0-merror:0.199474\tvalidation_1-merror:0.220539\n",
            "[42]\tvalidation_0-merror:0.198695\tvalidation_1-merror:0.220707\n",
            "[43]\tvalidation_0-merror:0.197769\tvalidation_1-merror:0.220286\n",
            "[44]\tvalidation_0-merror:0.196275\tvalidation_1-merror:0.219613\n",
            "[45]\tvalidation_0-merror:0.195707\tvalidation_1-merror:0.219108\n",
            "[46]\tvalidation_0-merror:0.194739\tvalidation_1-merror:0.218266\n",
            "[47]\tvalidation_0-merror:0.194192\tvalidation_1-merror:0.217172\n",
            "[48]\tvalidation_0-merror:0.193287\tvalidation_1-merror:0.217172\n",
            "[49]\tvalidation_0-merror:0.192466\tvalidation_1-merror:0.216667\n",
            "[50]\tvalidation_0-merror:0.19194\tvalidation_1-merror:0.216835\n",
            "[51]\tvalidation_0-merror:0.191225\tvalidation_1-merror:0.216077\n",
            "[52]\tvalidation_0-merror:0.190278\tvalidation_1-merror:0.215152\n",
            "[53]\tvalidation_0-merror:0.18971\tvalidation_1-merror:0.21431\n",
            "[54]\tvalidation_0-merror:0.189205\tvalidation_1-merror:0.214478\n",
            "[55]\tvalidation_0-merror:0.188279\tvalidation_1-merror:0.212879\n",
            "[56]\tvalidation_0-merror:0.187184\tvalidation_1-merror:0.212795\n",
            "[57]\tvalidation_0-merror:0.186385\tvalidation_1-merror:0.211953\n",
            "[58]\tvalidation_0-merror:0.185501\tvalidation_1-merror:0.211448\n",
            "[59]\tvalidation_0-merror:0.18487\tvalidation_1-merror:0.211448\n",
            "[60]\tvalidation_0-merror:0.184364\tvalidation_1-merror:0.211364\n",
            "[61]\tvalidation_0-merror:0.183586\tvalidation_1-merror:0.210859\n",
            "[62]\tvalidation_0-merror:0.183123\tvalidation_1-merror:0.21069\n",
            "[63]\tvalidation_0-merror:0.182302\tvalidation_1-merror:0.210354\n",
            "[64]\tvalidation_0-merror:0.182029\tvalidation_1-merror:0.210522\n",
            "[65]\tvalidation_0-merror:0.181839\tvalidation_1-merror:0.209512\n",
            "[66]\tvalidation_0-merror:0.181145\tvalidation_1-merror:0.209259\n",
            "[67]\tvalidation_0-merror:0.180745\tvalidation_1-merror:0.209259\n",
            "[68]\tvalidation_0-merror:0.180156\tvalidation_1-merror:0.208923\n",
            "[69]\tvalidation_0-merror:0.179735\tvalidation_1-merror:0.208923\n",
            "[70]\tvalidation_0-merror:0.179398\tvalidation_1-merror:0.208754\n",
            "[71]\tvalidation_0-merror:0.178767\tvalidation_1-merror:0.208923\n",
            "[72]\tvalidation_0-merror:0.17822\tvalidation_1-merror:0.208923\n",
            "[73]\tvalidation_0-merror:0.177946\tvalidation_1-merror:0.209091\n",
            "[74]\tvalidation_0-merror:0.176684\tvalidation_1-merror:0.208502\n",
            "[75]\tvalidation_0-merror:0.176157\tvalidation_1-merror:0.207997\n",
            "[76]\tvalidation_0-merror:0.175231\tvalidation_1-merror:0.207576\n",
            "[77]\tvalidation_0-merror:0.174958\tvalidation_1-merror:0.208165\n",
            "[78]\tvalidation_0-merror:0.174579\tvalidation_1-merror:0.206313\n",
            "[79]\tvalidation_0-merror:0.17399\tvalidation_1-merror:0.206145\n",
            "[80]\tvalidation_0-merror:0.173695\tvalidation_1-merror:0.205556\n",
            "[81]\tvalidation_0-merror:0.17338\tvalidation_1-merror:0.205135\n",
            "[82]\tvalidation_0-merror:0.173211\tvalidation_1-merror:0.205219\n",
            "[83]\tvalidation_0-merror:0.172727\tvalidation_1-merror:0.204798\n",
            "[84]\tvalidation_0-merror:0.172306\tvalidation_1-merror:0.204798\n",
            "[85]\tvalidation_0-merror:0.171928\tvalidation_1-merror:0.204714\n",
            "[86]\tvalidation_0-merror:0.171907\tvalidation_1-merror:0.204545\n",
            "[87]\tvalidation_0-merror:0.17138\tvalidation_1-merror:0.204209\n",
            "[88]\tvalidation_0-merror:0.170581\tvalidation_1-merror:0.204545\n",
            "[89]\tvalidation_0-merror:0.17037\tvalidation_1-merror:0.204293\n",
            "[90]\tvalidation_0-merror:0.169634\tvalidation_1-merror:0.204461\n",
            "[91]\tvalidation_0-merror:0.169423\tvalidation_1-merror:0.204545\n",
            "[92]\tvalidation_0-merror:0.169213\tvalidation_1-merror:0.204377\n",
            "[93]\tvalidation_0-merror:0.168624\tvalidation_1-merror:0.204545\n",
            "[94]\tvalidation_0-merror:0.168119\tvalidation_1-merror:0.204377\n",
            "[95]\tvalidation_0-merror:0.167908\tvalidation_1-merror:0.204377\n",
            "[96]\tvalidation_0-merror:0.167551\tvalidation_1-merror:0.204545\n",
            "[97]\tvalidation_0-merror:0.167424\tvalidation_1-merror:0.204461\n",
            "[98]\tvalidation_0-merror:0.167109\tvalidation_1-merror:0.204377\n",
            "[99]\tvalidation_0-merror:0.166561\tvalidation_1-merror:0.204293\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, j_jobs=-1,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='multi:softprob', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlimPPpA4KlT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "f20d67de-6ccb-4d09-8f81-6eec082c6fba"
      },
      "source": [
        "results = model.evals_result()\n",
        "train_error = results['validation_0']['merror']\n",
        "val_error = results['validation_1']['merror']\n",
        "epoch = range(1, len(train_error)+1)\n",
        "plt.plot(epoch, train_error, label='Train')\n",
        "plt.plot(epoch, val_error, label='Validation')\n",
        "plt.legend()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f77871db390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF7-ml6BhRRf",
        "colab_type": "text"
      },
      "source": [
        "## Try adjusting these hyperparameters\n",
        "\n",
        "#### Random Forest\n",
        "- class_weight (for imbalanced classes)\n",
        "- max_depth (usually high, can try decreasing)\n",
        "- n_estimators (too low underfits, too high wastes time)\n",
        "- min_samples_leaf (increase if overfitting)\n",
        "- max_features (decrease for more diverse trees)\n",
        "\n",
        "#### Xgboost\n",
        "- scale_pos_weight (for imbalanced classes)\n",
        "- max_depth (usually low, can try increasing)\n",
        "- n_estimators (too low underfits, too high wastes time/overfits) — Use Early Stopping!\n",
        "- learning_rate (too low underfits, too high overfits)\n",
        "\n",
        "For more ideas, see [Notes on Parameter Tuning](https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html) and [DART booster](https://xgboost.readthedocs.io/en/latest/tutorials/dart.html)."
      ]
    }
  ]
}